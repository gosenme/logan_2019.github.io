---
title: 重学 Go 语言：基础篇-39
---
<article id="topicContainer" class="column_content"><h2 class="topic_title"></h2><div><p><div class="toc">
<ul>
<li><ul>
<li><a href="#42falsesharing">4-2 False Sharing 的问题</a><ul>
<li><a href="#02vs">02 数组指针 vs 指针数组</a></li>
<li><a href="#01">01 是不是数组就一定能分配在栈上？</a></li>
<li><a href="#02falsesharing">02 False Sharing的问题</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</p>
<h2 id="42falsesharing">4-2 False Sharing 的问题</h2>
<h3 id="02vs">02 数组指针 vs 指针数组</h3>
<pre><code class="go language-go">func main() {
    var a [3]int
    var b [3]*int
    var p *[3]int = &amp;a
    p[0] = 10
    var p1 *int = &amp;a[2]
    *p1 = 30
    fmt.Println(a, b)
}
</code></pre>
<ul>
<li>数组指针引用整个目标数组。</li>
<li>数组指针元素类型为指针。</li>
<li>可使用数组指针访问和赋值元素，可直接获取元素地址。</li>
</ul>
<p>数组指针指的是数组的起始位置，用一个变量保存这个地址，这个变量叫做数组指针。变量要分配内存，这个变量里面存了某一个地址，而地址只是抽象的序号，所以指针和地址并不是一回事。数组指针是一个变量保存了数组的起始位置，指针数组是数组里面保存的是指针，就是说一个数组的元素类型是指针的情况下叫指针数组，等于整数数组整数换成指针而已。</p>
<p>上面例子中<code>a</code>和<code>b</code>都是普通的数组，<code>a</code>存的是整数，<code>b</code>存的是指针。<code>p</code>是数组的指针，数组本质上是一个单一对象，对它取指针操作，虽然指针指向数组起始地址，实际上包括完整的内存访问空间，我们称为数组的指针。数组的指针和数组本身操作没什么区别，支持语法糖访问。<code>p1</code>取的是某个元素的指针，不能用下标的方式退化为普通的指针操作。</p>
<pre><code class="go language-go">func main() {
    var x [100]int
    p := &amp;x
    p[1] = 100 //语法糖(*p)[1]
    println(p[1])

    p2 := &amp;p
    println((*p2)[1])

    p3 := &amp;x[30]
    *p3 = 99
    println(x[30])
}
</code></pre>
<p>上面例子数组<code>x</code>，<code>p</code>取它的地址返回它的指针，<code>p</code>的类型是<code>*[100]int</code>。数组的指针指的是把这个数组当成单一对象来对待，可以通过类型的指针进行赋值<code>p[1] = 100</code>，这是一种语法糖，相当于自动转换为<code>(*p)[1]</code>。<code>p2</code>是二级指针，取指针<code>p</code>的指针，语法糖仅支持一级指针，不支持<code>p2[1]</code>写法，需要指定<code>(*p2)[1]</code>。</p>
<p>数组支持直接取元素的地址。比如<code>p3 := &amp;x[30]</code>，<code>p3</code>不能通过下标赋值，下标只是数组的方式。<code>p3</code>是单个元素的地址，是把一个块当成整数处理。这两种指针类型是不一样的，数组的指针是完整的，可以用语法糖下标的方式，如果取的是其中元素从数组演化成单一对象只能针对元素操作，不是操作整个数组而是操作其中一个元素<code>*p3 = 99</code>。所以要分清楚数组的指针、元素的指针。</p>
<p>指针数组<code>var x [100]*int</code>是一个普通的数组。区别就是每个元素是一个指针，指向某个对象。所以数组的指针和指针数组不一样的，数组的指针是内存块而言，指针数组和整数数组字符串数组没什么区别。</p>
<pre><code class="go language-go">func main() {
    var x [100]unsafe.Pointer //任意类型的指针

    a := 1
    x[0] = unsafe.Pointer(&amp;a) //整数的指针

    s := "abc"
    x[1] = unsafe.Pointer(&amp;s) //字符串的指针
}
</code></pre>
<h3 id="01">01 是不是数组就一定能分配在栈上？</h3>
<p>很多时候我们用数组优化会非常好，但是数组未必分配到栈上，下面的例子声明一个数组并把它的地址打印出来。</p>
<pre><code class="go language-go">func escape() {
    var d [10]int
    fmt.Println(&amp;d)
}
</code></pre>
<pre><code class="bash language-bash">$ go run -gcflags "-m" main.go
# command-line-arguments
&amp;d escapes to heap
&amp;d escapes to heap
moved to heap: d
escape ... argument does not escape
&amp;[0 0 0 0 0 0 0 0 0 0]
</code></pre>
<p>我们发觉<code>&amp;d</code>逃逸到堆上了，因为<code>fmt.Println</code>接收参数的是接口对象，接口对象必须复制原始对象内部需要储存相应的信息，原始数据必须保证生命周期必须要放到堆上面。</p>
<h3 id="02falsesharing">02 False Sharing的问题</h3>
<p><code>cache miss</code>就是cache没有命中，在数组操作时候可能会写一些性能有问题的代码。</p>
<p>CPU的结构是多核，核内部每个都有L1、L2缓存，L3是共享的，L1分成指令缓存和数据缓存。</p>
<p>当我们获取数据的时候首先在缓存中查，查不到到主存中查，查到存到缓存中，问题是数据不是完全按对象缓存，因为缓存时候CPU根本不知道对象结构是什么样的，所有的内存都是字节，它把空间分成多个等长的块，每个块称之为<code>cache line</code>，每次缓存是固定大小的块，这个块可能是64字节。</p>
<p>假如一个数组，一个块缓存可能是多个元素，假设<code>cpu0</code>访问index=0数据，<code>cpu1</code>访问index=1数据，这样<code>cpu0</code>和<code>cpu1</code>除了自己操作的数据以外还缓存了别人的数据，假如<code>cpu0</code>和<code>cpu1</code>并发执行两个任务，<code>cpu0</code>的index=0做加法的时候整个<code>cache line</code>发生变化了，因为cpu内部<code>cache line</code>是一整块，所以两个<code>cache line</code>同时被两个CPU缓存，一旦修改里面的状态就会导致其他核同样的缓存块失效，<code>cpu0</code>上状态改变了<code>cpu1</code>必须同步，同样的<code>cpu1</code>修改数据<code>cpu0</code>必须同步，<code>cpu0</code>和<code>cpu1</code>频繁进行缓存同步会造成缓存效应非常的差。我们管这种现象叫做<code>False Sharing</code>，这种缓存是有问题的。</p>
<p>这个原理是因为CPU不清楚内部什么数据结构，它是按照64字节来缓存一个块，如果<code>cpu0</code>和<code>cpu1</code>都持有这64字节，任何字节发生改变都需要同步到其他CPU核。</p>
<pre><code class="go language-go">func falseSharing() {
    var wg sync.WaitGroup

    // 有4个计数器，有4个并发任务，每个任务拿其中一个来作为计数器使用
    var counter [4]int

    for i := 0; i &lt; len(counter); i++ {
        wg.Add(1)

        go func(idx int) {
            defer wg.Done()

            for n := 0; n &lt; 1000000; n++ {
                counter[idx]++
            }
        }(i)
    }
    wg.Wait()
}
</code></pre>
<p>上面的这段代码，有<code>False Sharing</code>问题，我们修改一下：</p>
<pre><code class="go language-go">func falseSharing() {
    var wg sync.WaitGroup

    var counter [4]struct {
        data int
        _    [64 - 8]byte
    }

    for i := 0; i &lt; len(counter); i++ {
        wg.Add(1)

        go func(idx int) {
            defer wg.Done()

            for n := 0; n &lt; 1000000; n++ {
                counter[idx].data++
            }
        }(i)
    }
    wg.Wait()
}
</code></pre>
<p>每个计数器一条<code>cache line</code>，修改计数器只是修改0号位，相互之间没有重叠的地方，这样就不会导致缓存失效问题。怎么样保证每个计数器调用单独的<code>cache line</code>，简单做法就是用来补位，需要补位字段，提高性能。</p>
<pre><code class="go language-go">func test() {
    var counter [8]struct {
        x int
        // _ [64 - 8]byte
    }
    var wg sync.WaitGroup
    wg.Add(len(counter))
    for i := 0; i &lt; len(counter); i++ {
        go func(id int) {
            for n := 0; n &lt; 100000; n++ {
                counter[id].x++
            }
            wg.Done()
        }(i)
    }
    wg.Wait()
}

func BenchmarkTest(b *testing.B) {
    b.Run("nopad", func(b *testing.B) {
        for i := 0; i &lt; b.N; i++ {
            test1()
        }
    })
    b.Run("pad", func(b *testing.B) {
        for i := 0; i &lt; b.N; i++ {
            test2()
        }
    })
}
</code></pre>
<blockquote>
  <p>false sharing; cache line; MESI, RFO</p>
</blockquote>
<p>下面命令查看系统<code>cache line</code>大小：</p>
<pre><code class="bash language-bash">$ cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size
$ cat /proc/cpuinfo | grep cache_alignment
</code></pre>
<p>mheap.go文件</p>
<p>测试样本有八个计数器，每个计数器是个结构体，根据索引访问每个是独立的计数器，没有数据竞争因为不会访问相邻的内存。区别在于有一行用来补位，结果带来这么大的性能差别，这就是所谓的缓存共会不会失效的问题。</p>
<p>CPU有一套自己缓存体系，CPU没有办法直接访问内存，现代CPU所有的数据都是从它的缓存获取的。L1缓存分为指令和数据，CPU有自己独立的L1缓存、L2缓存，所有CPU共享L3级缓存，实际上是这样架构。当访问数据的时候，它会优先一级一级缓存去找，找不到才会到主存里找。缓存器负责从主存和L3、L2、L1取数据，写数据反过来一个方向。</p>
<p>一份数据可能同时被两个CPU缓存，读没有问题。假设CPU1修改数据，它会向地址总线发出一个请求对修改数据要求独占，这条指令在地址总线被其他CPU监听，会立即把自己缓存里相同的数据缓存失效，导致相同的数据在其他的CPU核立即失效，从共享变成独占直到修改成功下次访问重新刷新缓存。</p>
<p>CPU实际上不理解数据结构，它的缓存器存的是一块缓存，缓存分成一块一块的，每块称之为行，每行称之为<code>cahce line</code>缓存行。所谓的独占、修改、共享是以缓存行为单位的。缓存行通常情况下64字节。当缓存数据的时候，它会以某个对象起始的连续的64个字节内存一次性缓存一行，这就是所谓的缓存空间局部性原则，接下来很大概率读取相邻的内存，也就意味着修改同样是缓存行，拿到这一行的独占权。会导致其他CPU相同的这一行数据失效，修改成功要重新刷新缓存，这就是所谓的缓存行的概念。</p>
<p>每个计数器是8字节，一共是8个64字节正好一缓存行，意味着数据正好会被刷到CPU1的一行里，CPU2、CPU3、CPU4都有同样的数组，这样同一个数组会被所有CPU内核缓存起来。如果不了解这个背景知识，我们认为CPU1只修改一小块，CPU2修改一小块，从代码上看它修改内存不相等。但是对cpu来说它按照一整行64字节来锁定的，它不关心在64字节里访问哪一块，64字节是一个整体。当CPU1修改数据的时候要独占64字节会导致CPU2整个缓存行全部失效。CPU2要修改也要把缓存重新刷回来。任何一方修改计数器都会导致其他cpu里缓存行全部失效。</p>
<p>怎么解决呢？用补位的方式占64字节。这样CPU1刷到是64字节，CPU1和CPU2刷的数据是不一样的，数据不相交。CPU2缓存数据不会出现在CPU1里。用补位把原来挤在一块凑成一个cache line。通过补位的方式每一个元素占64字节不被所有CPU共享，每个CPU都持有一条独立的行，这样缓存就能正常工作。尤其是在服务器编程核数量越多的情况下，影响会越来越严重。</p>
<p>对于伪共享背后有一整套的理论，以后写相关并发的时候要考虑到伪共享可能会造成一些性能损失。它跟语言无关，使用任何的语言最终都跟cpu打交道，都可能会面临这样的一些问题。</p></div></article>