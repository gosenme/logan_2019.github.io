---
title: 重学 Go 语言：基础篇-55
---
<article id="topicContainer" class="column_content"><h2 class="topic_title"></h2><div><h3 id="18">18 预分配字典空间</h3>
<pre><code class="go language-go">func test1() map[int]int {
    m := make(map[int]int)
    for i := 0; i &lt; 10000; i++ {
        m[i] = i
    }
    return m
}
func test2() map[int]int {
    m := make(map[int]int, 10000)
    for i := 0; i &lt; 10000; i++ {
        m[i] = i
    }
    return m
}

func BenchmarkTest(b *testing.B) {
    b.Run("normal", func(b *testing.B) {
        for i := 0; i &lt; b.N; i++ {
            _ = test1()
        }
    })
    b.Run("prealloc", func(b *testing.B) {
        for i := 0; i &lt; b.N; i++ {
            _ = test2()
        }
    })
}
</code></pre>
<p>第一个我们不对字典提前设置容量，我们往里面去追加数据时候让它动态去扩容。第二个我们提前设置足够大的空间，来减少中间的扩容和内存分配操作。</p>
<pre><code>$ go test -bench . -benchmem
BenchmarkTest/normal-4   2000 937146 ns/op 687428 B/op 278 allocs/op
BenchmarkTest/prealloc-4 3000 523648 ns/op 322307 B/op 12 allocs/op
</code></pre>
<p>我们可以看到它们的性能差别并不大，最大的问题是每次操作分配多大空间、有多少次内存分配操作。例如278到12。</p>
<p>提前对字典设置合理的容量有助于改善程序的性能。当然在不同的语言里面对哈希表的实现算法可能不一样，这个不具备通用性，但是给我们的思路在于学习一门语言应该了解下字典怎么去实现的。</p>
<p>字典是否需要预分配空间的问题，视情况，如果字典存储数据非常多，大概知道数字范围，可以考虑提前分配，避免在插入数据的过程中频繁扩容，频繁数据迁移带来性能上的损失。</p>
<p>第一个版本直接创建，自己去扩容。第二种提前分配。对比一下两者的性能差异。主要的性能消耗是扩容，扩容除了分配内存还要数据迁移。</p>
<p>尽可能让基础的数组足够大，因为变大了以后分布会均摊，每个链表本身就会短很多。所以我们预分配容量的时候很重要，比如说可以预估一下，一些算法在实验可以估算出合理的百分比。比如你存储10个的话，那么它真正的合理空间百分比是(100+50)%，因为我们知道有的地方肯定是空的无法命中，肯定有些浪费，所们真实分配的空间要比真实存储KeyValue数据大很多。所以理论上提前计算好这种容量。举个例子。</p>
<pre><code class="go language-go">// Picking loadFactor: too large and we have lots of overflow
// buckets, too small and we waste a lot of space. I wrote
// a simple program to check some stats for different loads:
// (64-bit, 8 byte keys and values)
//  loadFactor    %overflow  bytes/entry     hitprobe    missprobe
//        4.00         2.13        20.77         3.00         4.00
//        4.50         4.05        17.30         3.25         4.50
//        5.00         6.85        14.77         3.50         5.00
//        5.50        10.55        12.94         3.75         5.50
//        6.00        15.27        11.67         4.00         6.00
//        6.50        20.90        10.79         4.25         6.50
//        7.00        27.14        10.15         4.50         7.00
//        7.50        34.03         9.73         4.75         7.50
//        8.00        41.10         9.40         5.00         8.00
//
// %overflow   = percentage of buckets which have an overflow bucket
// bytes/entry = overhead bytes used per key/value pair
// hitprobe    = # of entries to check when looking up a present key
// missprobe   = # of entries to check when looking up an absent key
//
// Keep in mind this data is for maximally loaded tables, i.e. just
// before the table grows. Typical tables will be somewhat less loaded.
</code></pre>
<p>在<code>hashmap.go</code>文件里，我们可以看出通过大量的实验计算出类似这样的数据表，通过这个数据表决定一个指数，比如你申请10个KeyValue存储空间，那么理论上处理多大是最合理的性能最好的，空间利用率最高的，这些东西都是通过大量的实验计算出来的，因为选择一种哈希算法以后它会通过大量实验统计这种结果。</p>
<pre><code class="go language-go">// makemap implements a Go map creation make(map[k]v, hint)
// If the compiler has determined that the map or the first bucket
// can be created on the stack, h and/or bucket may be non-nil.
// If h != nil, the map can be created directly in h.
// If bucket != nil, bucket can be used as the first bucket.
func makemap(t *maptype, hint int64, h *hmap, bucket unsafe.Pointer) *hmap {
    //......

    // find size parameter which will hold the requested # of elements
    B := uint8(0)
    for ; overLoadFactor(hint, B); B++ {
    }

    // allocate initial hash table
    // if B == 0, the buckets field is allocated lazily later (in mapassign)
    // If hint is large zeroing this memory could take a while.
    buckets := bucket
    var extra *mapextra
    if B != 0 {
        var nextOverflow *bmap
        buckets, nextOverflow = makeBucketArray(t, B)
        if nextOverflow != nil {
            extra = new(mapextra)
            extra.nextOverflow = nextOverflow
        }
    }

    // initialize Hmap
    if h == nil {
        h = (*hmap)(newobject(t.hmap))
    }
    h.count = 0
    h.B = B
    h.extra = extra
    h.flags = 0
    h.hash0 = fastrand()
    h.buckets = buckets
    h.oldbuckets = nil
    h.nevacuate = 0
    h.noverflow = 0

    return h
}
</code></pre>
<p>我们可以看到创建函数的时候，我们想存储KeyValue数量和真实分配的存储空间是不一样的。</p>
<pre><code class="go language-go">// overLoadFactor reports whether count items placed in 1&lt;&lt;B buckets is over loadFactor.
func overLoadFactor(count int64, B uint8) bool {
    // TODO: rewrite to use integer math and comparison?
    return count &gt;= bucketCnt &amp;&amp; float32(count) &gt;= loadFactor*float32((uint64(1)&lt;&lt;B))
}
</code></pre>
<p><code>overLoadFactor</code>会计算出很合理的指数，这个指数才是它真正意义上的存储空间。存10个KeyValue，真实存储空间肯定比这个大，因为其中某些地方没有办法命中，肯定有空间浪费。所以理论上我们是提前提供足够大的空间有助于改善性能。</p>
<p>因为Go语言本身也会做扩容处理，因为它会发觉单个链表的节点可能会过长，比如说申请容量为10的字典，但是存储1000个，链表就变得非常的长。Go的做法会把10进行扩容，可能10*2一直扩容下去做到尽可能让每个链表变短。那么扩容的时候就会涉及到重新分配数组，重新进行哈希。</p>
<h3 id="18-1">18 预置容量的差异</h3>
<p>对于很多容器对象都会涉及到预分配内存的问题。比如说切片，我们知道切片有两种创建方式。</p>
<pre><code class="go language-go">func main() {
    s1 := make([]byte, 0) //表示动态去扩容，可能在8项扩张一次，16、32扩张，会涉及到很多次内存分配操作
    //任何时候内存分配操作都会有很严重的性能问题，除了分配内存以外，还需要把原来数据拷贝过来
    s2 := make([]byte, 0, 10000) //提前分配足够大的底层数组，好处内存是一次性分配的，只要没有超出之前不需要重新扩张。
}
</code></pre>
<p>对于容器对象，当然指的是这个容器可能会存很多数据，如果数据量很小可能就不在乎，因为大部分都会有默认大小，比如内置默认可以存8个。数据量比较多的提前给个容量可以减少扩张行为，就减少了内存分配操作和复制操作。对于容器类对象，一般情况下我们尽量给它一个初始化值，减少性能压力。</p>
<p>性能测试函数，第一个我们创建一个字典，但是没有给它默认容量也就是说它得动态增加。第二个函数提前给他预置容量，接下来调用test函数把字典填满，我们看下提供初始化容量和不提供初始化容量的性能差异有多大。先看填充字典的性能有多大差异。</p>
<pre><code class="go language-go">func test(m map[int]int) {
    for i := 0; i &lt; 1000000; i++ {
        m[i] = i
    }
}

func BenchmarkMap1(b *testing.B) {
    m := make(map[int]int)
    b.ResetTimer()

    for i := 0; i &lt; b.N; i++ {
        // m := make(map[int]int)
        test(m)
    }
}

func BenchmarkMap2(b *testing.B) {
    m := make(map[int]int, 1000000)
    b.ResetTimer()

    for i := 0; i &lt; b.N; i++ {
        // m := make(map[int]int, 1000000)
        test(m)
    }
}
</code></pre>
<p>我们可以看到预置容量方式在填充过程中内存分配次数远远少于没有初始化容量的数量。</p>
<p>接下来测试下创建过程也计算在内，我们发觉它们性能比较接近，说白了提前预置容量它需要把所有keyvalue数据准备好。我们多数情况下不会这样做，因为我们创建大字典时候往往会重复使用字典。</p></div></article>