---
title: SSM 搭建精美实用的管理系统-23
---
<article id="topicContainer" class="column_content"><h2 class="topic_title"></h2><div><h3 id="221">22.1 项目集群优化</h3>
<p>项目初期，为了快速开发和上线，大家一般会选择在单机上部署项目及相关组件，Web 服务器选择 Tomcat，系统实现可能选用 SSM 框架+JSP/HTML，数据库选择 MySQL 。正如目前的 ssm-demo 项目，将数据库和 Tomcat 部署在一台服务器主机上，系统已可正常运行且功能正常，此时的部署方案如下：</p>
<p><img src="https://images.gitbook.cn/a5153da0-b4f5-11e8-8cec-e73b093e0df7" alt="single" /></p>
<p>之后，随着访问量持续增加，系统将逐渐遭遇性能瓶颈，也将越来越无法满足需求，这时业界的通常做法可能就是系统优化，正如前几篇文章中提到的那样，优化 DAO 层、增加缓存层等等。这时，数据库查询可能不再是系统变慢的主要瓶颈，而是单机性能无法满足越来越大的用户请求，因此需要增加 Tomcat 服务器，把应用服务器从一台增至两台甚至多台，把用户请求分散到不同的服务器中，从而缓解单机瓶颈带来的隐患，提高系统负载能力，此时的优化方案如下图所示：</p>
<p><img src="https://images.gitbook.cn/ae442990-b4f5-11e8-8cec-e73b093e0df7" alt="cluster" /></p>
<h3 id="222">22.2 集群与负载均衡</h3>
<p>如下图所示，服务器集群是指将很多服务器集中起来提供同一种服务，在客户端看来好像只有一个服务器。相比于单机部署，集群拥有更多的计算资源，可提升系统的处理能力和响应速度。一旦某服务器上安装并运行了集群服务，该服务器即可加入集群。集群可以减少单点故障数量，并且实现了服务器资源的高可用性。</p>
<p><img src="https://images.gitbook.cn/be5c0910-b4f5-11e8-ba74-87184af855a0" alt="nginx-tomcat" /></p>
<p>当然，仅仅实现集群还不够，系统中依然需要负载均衡器来管理集群，以使集群中的机器可以更好地为系统提供服务。实现服务器集群主要是为负载均衡（有两台以上的服务器或站点提供服务）服务器服务，将来自客户端的请求，基于负载均衡算法分配到集群的机器中，从而避免一台服务器因负载过高而出现故障。当某个节点出现故障时，负载均衡器会自动规避该故障节点，使整个系统依然可以正常运行，用户依然能正常访问服务。</p>
<p>接下来，我们将详细介绍如何搭建 Tomcat 集群，并将 Nginx 作为负载均衡器实现集群的负载均衡，最后会介绍基本的负载均衡算法，让大家可以更清晰深刻地认识负载均衡这一技术点。</p>
<h3 id="223nginx">22.3 Nginx 安装</h3>
<p>搭建之前，首先需要安装 Nginx 和 Tomcat，Tomcat 的安装前面课程中已讲过，这里只介绍 Nginx 的安装过程。</p>
<h4 id="1">1. 安装</h4>
<p>Nginx 的下载地址如下：</p>
<blockquote>
  <p>http://nginx.org/en/download.html</p>
</blockquote>
<p>选择时尽量选择 Stable 稳定版本，点击对应版本下载即可。</p>
<p><img src="https://images.gitbook.cn/d65cbff0-b4f5-11e8-ba74-87184af855a0" alt="nginx-download" /></p>
<p>之后将安装包解压，解压后可以看到 Nginx 的目录结构：</p>
<p><img src="https://images.gitbook.cn/e26f6ae0-b4f5-11e8-8cec-e73b093e0df7" alt="nginx-dictionary" /></p>
<h4 id="2nginx">2. 启动 Nginx</h4>
<p>进入安装目录，打开 cmd 命令行，执行命令：</p>
<pre><code>start nginx
</code></pre>
<p>启动窗口一闪而过，如何查看是否启动成功？我们打开任务管理器，在进程一栏可以看到两个 Nginx 服务正在运行，说明启动成功。</p>
<p>如果想停止 Nginx，在 cmd 命令行中运行命令 nginx -s stop 即可。</p>
<p><img src="https://images.gitbook.cn/efe21b00-b4f5-11e8-ba91-df426e0e62ac" alt="nginx-task" /></p>
<p>我们在浏览器访问 Nginx，输入 localhost 即可，Nginx 默认监听 80 端口，如果出现 Nginx 的默认欢迎页面，说明访问成功。</p>
<p><img src="https://images.gitbook.cn/0b8e9bd0-b4f6-11e8-ba74-87184af855a0" alt="nginx-start" /></p>
<h3 id="224">22.4 集群</h3>
<p>搭建 Tomcat 集群，至少需要两个 Tomcat 目录。如果已经存在 Tomcat 目录，把 Tomcat 再复制一份就可以了，过程如下：</p>
<p><img src="https://images.gitbook.cn/7e7ec450-b4fe-11e8-ba91-df426e0e62ac" alt="tomcat-double" /></p>
<p>这个时候两个 Tomcat 服务器的所有设置和文件都是相同的，为了实现集群功能并区分不同的 Tomcat，需要对 Tomcat 的设置和页面文件做部分修改。</p>
<p>首先修改 Tomcat 的端口设置。分别进入两个 Tomcat 服务器的 conf 目录，打开 server.xml 配置文件并做修改，过程如下：</p>
<p><img src="https://images.gitbook.cn/368aa310-b4f6-11e8-8cec-e73b093e0df7" alt="tomcat-port-set" /></p>
<p>首先将 Tomcat1 的三个端口分别修改为 8081 、8082 、8083，浏览器访问 Tomcat1 使用的端口号为 8082，之后修改 Tomcat2 的三个端口号，分别为 8084 、8085 、8086，浏览器访问 Tomcat2 使用的端口号为 8085 。</p>
<p>第一处端口修改，如下图所示：</p>
<p><img src="https://images.gitbook.cn/41e066a0-b4f6-11e8-ba74-87184af855a0" alt="tomcat-server-xml1" /></p>
<p>第二处端口修改，如下图所示：</p>
<p><img src="https://images.gitbook.cn/49b5b600-b4f6-11e8-a745-899a3978c7b7" alt="tomcat-server-xml2" /></p>
<p>第三处端口修改，如下图所示：</p>
<p><img src="https://images.gitbook.cn/56e40a20-b4f6-11e8-a745-899a3978c7b7" alt="tomcat-server-xml3" /></p>
<p>大家搭建时，请注意以上三处端口的修改，我将端口设置为 808X，你在本地测试时可以自行设置端口号，只要不发生冲突即可。</p>
<p>端口修改完成后，还需要修改两个 Tomcat 的 index.jsp 页面。这两份文件是相同的，为了对 Tomcat1 和 Tomcat2 的页面进行区分，需要对页面内容进行微小的调整，过程如下：</p>
<p><img src="https://images.gitbook.cn/bf2a3f70-b4fe-11e8-ba91-df426e0e62ac" alt="update-index" /></p>
<p>进入 webapps/ROOT 目录，修改 index.jsp 文件，在 Tomcat1 的 index 页面添加提醒文字 “ 端口号为 8082 的 Tomcat 服务器 ”，之后对 Tomcat2 的 index 页面进行修改，添加提醒文字 “ 端口号为 8085 的 Tomcat 服务器 ”，这样我们就可以很容易地区分两台 Tomcat 服务器了。</p>
<p>之后分别进入两个 Tomcat 的 bin 目录，点击 startup 文件，启动服务器。如果两台服务器都能正常启动，集群搭建的第一步就完成了。</p>
<p><img src="https://images.gitbook.cn/da352910-b4fe-11e8-ba74-87184af855a0" alt="tomcat-start" /></p>
<p>打开浏览器并在地址栏中分别输入： http://localhost:8082  和 http://localhost:8085 两个地址，便可访问 Tomcat1 和 Tomcat2 服务器，结果如下：</p>
<p><img src="https://images.gitbook.cn/7e7f5a30-b4f6-11e8-ba91-df426e0e62ac" alt="visit-tomcat" /></p>
<p>两个 Tomcat 的端口不同，访问地址不同，页面上也有不同的文字提示。</p>
<h3 id="225">22.5 负载均衡</h3>
<h4 id="1-1">1. 负载均衡的优点</h4>
<p>负载均衡具有以下四个优点：</p>
<ul>
<li><p>提高系统吞吐量：搭建负载均衡的集群系统，部署多台 Tomcat 服务器，可提高系统的处理能力和系统吞吐量；</p></li>
<li><p>降低单点故障：有效降低单点故障率，增加服务可用性；</p></li>
<li><p>降低对外网端口的依赖：负载均衡下只需要一个外网端口，但可以负载到内网多个 Tomcat 服务器上；</p></li>
<li><p>不停机，即可升级系统：很多情况下，升级服务端系统文件或者增减 Tomcat 服务器数量后，需要重启服务以应用最新程序，而通过 Nginx 负载，不停服务即可完成重启过程。</p></li>
</ul>
<h4 id="2nginx-1">2. Nginx 实现负载均衡</h4>
<p>前面，我们已经完成了 Tomcat 服务器集群的搭建，但这个集群还不完整。要访问它们，依然只能通过各自的地址+端口号访问，这两台服务器依然 “ 各自为政 ”，无法作为一个整体对外提供服务。要想使该集群的功能更加完整，还需要加入负载均衡器，即 Nginx 。</p>
<h4 id="3">3. 修改配置文件</h4>
<p>进入 Nginx 安装目录，编辑 conf 目录下的 nginx.conf 配置文件，在 http 节点下加入 upstream 节点，增加如下内容如下：</p>
<pre><code>upstream HA-tomcat{
    server locahost:8082;
    server locahost:8085;
}
</code></pre>
<p>在 server 节点下面的 location/ 节点中添加如下内容：</p>
<pre><code>proxy_pass http://HA-tomcat;
</code></pre>
<p>HA-tomcat 使用 upstream 指令配置后端服务器组，代理两个 Tomcat 服务器，目前我们的集群只有两个节点，端口分别是我们刚才设置的 8082 和 8085，当然还可以继续向其中添加节点。</p>
<p>proxy_pass http://HA-tomcat; 配置了 Nginx 代理转发规则，当浏览器访问 http://localhost 时，Nginx 会将请求转发至 HA-tomcat 服务器组，之后，服务器组根据负载均衡算法将请求分配给相应的 Tomcat 服务器进行处理。</p>
<p>配置修改完成后，打开命令行，执行 nginx -s reload 命令重启 Nginx 服务，之后再访问 http://localhost ，可以看到此时出现的页面已经不是 Nginx 的默认欢迎页，而是两台 Tomcat 的页面，一直刷新页面可以看到请求已经被轮流分发到 Tomcat1 和 Tomcat2 服务器上，至此集群和负载功能搭建完成。</p>
<p><img src="https://images.gitbook.cn/9f818460-b4f6-11e8-ba74-87184af855a0" alt="nginx-tomcat-ha" /></p>
<h4 id="4nginx">4. Nginx 负载均衡算法</h4>
<p>前面，我们配置的负载均衡采用了默认的轮询方式，即每个请求按时间顺序逐一分配给不同的后端 Tomcat。然而，不同的业务需求也不同，相应地也需要不同的负载均衡方式，为此 Nginx 提供了以下五种负载均衡算法。</p>
<ul>
<li>轮询（默认）。</li>
</ul>
<p>每个请求按时间顺序逐一分配给不同的后端服务。后端某台服务器死机，会被自动剔除故障系统，以使用户的访问不受影响，前文中的 HA-tomcat 就使用了这种默认方式。</p>
<ul>
<li>weight（轮询权值）。</li>
</ul>
<p>weight 的值越大，被访问到的概率就越高。当后端服务器的性能不均衡时，可以考虑使用这种方式。可为主机设置更高的权值，以使主机资源得到合理高效利用，比如有三个 Tomcat 服务分别部署在两台 Linux 服务器上，其中一台 Linux 服务器配置较高，而另外一台较低，那么高配置 Linux 服务器上的 Tomcat 服务的权重可以设置得高一点，配置如下：</p>
<pre><code>    upstream HA-tomcat{
    server 192.168.90.1:8082 weight=20;
    server 192.168.90.2:8085 weight=10;
    server 192.168.90.2:8088 weight=10;
    }
</code></pre>
<p>192.168.90.1 机器的配置比较高，权重可以设置得大一些。</p>
<ul>
<li>ip_hash 。</li>
</ul>
<p>每个请求按访问 IP 的哈希结果分配，使来自同一个 IP 的访客固定访问一台后端服务器，配置方式如下：</p>
<pre><code>    upstream HA-tomcat{
    ip_hash;
    server 192.168.90.1:8082;
    server 192.168.90.2:8085;
    server 192.168.90.2:8088;
    }
</code></pre>
<ul>
<li>fair 。</li>
</ul>
<p>这是比 weight 、 ip<em>hash 更加智能的负载均衡算法。fair 算法可以根据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。Nginx 本身不支持 fair，如果需要这种调度算法，则必须安装 upstream</em>fair 模块。配置过程如下：</p>
<pre><code>    upstream HA-tomcat{
    server 192.168.90.1:8082;
    server 192.168.90.2:8085;
    server 192.168.90.2:8088;
    fair;
    }
</code></pre>
<ul>
<li>url_hash 。</li>
</ul>
<p>按访问 URL 的哈希结果来分配请求，使每个 URL 定向到一台后端服务器，可以进一步提高后端缓存服务器的效率。Nginx 本身不支持 url_hash ，如果需要这种调度算法，则必须安装 Nginx 的 hash 软件包。</p>
<h3 id="226">22.6 总结</h3>
<p>本文主要介绍了 Nginx+Tomcat 集群负载均衡的实现过程，主要步骤总结如下：</p>
<ul>
<li>安装 Nginx 和 Tomcat；</li>
<li>部署多台 Tomcat；</li>
<li>修改 Tomcat 配置文件 server.xml 端口；</li>
<li>Nginx 配置负载均衡；</li>
<li>分别启动 Tomcat 集群和 Nginx 。</li>
</ul>
<p>注意事项主要有：</p>
<ul>
<li>系统中如果开启了防火墙，很可能导致端口被屏蔽而无法访问，因此在设置端口时需要将端口规则过滤掉；</li>
<li>需保证 Tomcat 服务能正常启动；</li>
<li>Nginx 配置需正确，可以使用 nginx -t 验证配置文件。</li>
<li>需保证 Nginx 正常启动，如有问题可以查看 Windows 任务管理器，看是否存在两个以上 Nginx 进程，如果存在，需关闭这些进程并重启 Nginx 服务；</li>
<li>针对不同的负载均衡算法，可以根据需要自行选择。</li>
</ul>
<p>希望大家可以通过实际操作加深对该文知识的理解，并能熟练掌握该技能。</p></div></article>