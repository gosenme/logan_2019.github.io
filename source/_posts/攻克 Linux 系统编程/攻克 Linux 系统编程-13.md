---
title: 攻克 Linux 系统编程-13
---
<article id="topicContainer" class="column_content"><h2 class="topic_title"></h2><div><p>从根本上说，多线程编程的最终目的，就是最大限度地利用 CPU 的计算资源，尽量让所有的 CPU 核心都保持忙碌状态。</p>
<p>这里有两方面的意思：</p>
<ul>
<li>一是不要让 CPU 闲下来，保持它始终有工作做；</li>
<li>二是尽量让所有的 CPU 都有大体相当的负载，不要出现有的 CPU 核心很忙，而有的 CPU 核心却没事可做的情况。</li>
</ul>
<p>CPU 什么时候会闲下来呢？最常见的情况就是在等待 I/O 操作的时候，所以，当某些工作需要进行 I/O 操作时，就应该放在独立的线程中去完成，在 CPU 等待 I/O 操作的时间内，让其他的线程可以有机会获得 CPU 资源，从而提高程序的并行化水平。</p>
<p>此外，一个线程在同一时刻只能运行在一个 CPU 核心上。在多核已经成为主流配置的今天，如果一个应用只开启一两个线程，也不利于 CPU 的充分利用，所以，把一个应用中多个相干性很少的处理任务，分成多个不同的线程去执行，也能提高 CPU 的利用效率。</p>
<p>但是，服务于同一应用的多个线程，总是会有或多或少的联系，在程序表现上，就是不同的线程会时不时地访问或更新相同的共享数据，或者在某些特定的时间点上需要保证特定的线程执行顺序。这就要<strong>通过线程同步技术来实现</strong>。</p>
<p>在《第 05 课：理解线程实现，达成高效率与低复杂度》中，我们已经介绍过<strong>一种最常用的线程同步技术：互斥锁</strong>，它能保证在同一时刻最多只有一个线程能获取到某个共享数据的访问权限，其他同时试图获取访问权限的线程会被阻塞，直到前一个线程已经从临界区内退出。</p>
<p>互斥锁是一种非常有效，而且适用范围非常广的线程同步技术，但是，它也并不是万能的，好汉也需要帮手。</p>
<p><strong>本节课就来介绍下另外几种非常有用的帮手和补充</strong>，主要有：</p>
<ul>
<li>信号量</li>
<li>条件变量</li>
<li>读写锁</li>
<li>自旋锁</li>
</ul>
<p>每种技术都有特定的应用场景，在不同场景需求下灵活使用不同的同步技术，能够让读者的多线程程序运行得更加协调有序，从而更高效地完成任务。</p>
<h3 id="121">12.1 信号量</h3>
<p>我们在《第 06 课：探究进程间通信技术，优化数据传输效率》时就介绍过信号量，实际上，在 Linux 中，信号量也能用于线程间的同步。鉴于此，本节课会把使用信号量的线程和进程都叫做执行者。</p>
<p>信号量可以使执行者在某个需要的条件不满足时进入休眠，当其他的执行者更新了信号量，使需要的条件重新被满足时，系统会把睡眠的执行者唤醒继续执行。信号量中的数值，可以看作是当前需要执行的任务的数量。</p>
<p>递减信号量的操作相当于接取任务：</p>
<ul>
<li>如果接取成功，会使得信号量减 1；</li>
<li>如果当前信号量是 0，表示当前没有可接取的任务，这时任务领取者会被挂起，直到有其他执行者在该信号量上执行了递加操作。</li>
</ul>
<p>递加操作相当于发布新任务：</p>
<ul>
<li>如果发布成功，会使信号量加 1；</li>
<li>如果之前有被挂起的执行者，它会唤醒该执行者来接取这个任务；</li>
<li>如果当前的信号量已经达到了指定的容量，表示任务队列已满，那么任务发布的执行者会被挂起，直到任务队列中有空位留出。</li>
</ul>
<h4 id="1211">12.1.1 信号量的应用举例</h4>
<p>信号量常用在一个任务分发器对应多个工作线程的情形，并且通常与互斥锁配合使用。</p>
<p>一个比较简单的单任务队列实现方案是：</p>
<ul>
<li>在没有工作负载时，所有的工作线程都阻塞在某个信号量上；</li>
<li>当有任务需要处理时，任务分发器先把任务插入到任务队列； </li>
<li>然后增加信号量，使得其中的一个工作线程被唤醒，被唤醒的工作线程会从任务队列中取出一个任务去执行。</li>
</ul>
<p>在这个过程中，任务分发器向任务队列中追加任务和工作线程取出任务的时候，都需要使用互斥锁对任务队列进行保护。</p>
<p>想想房产中介的工作模式就可以对这种工作模型有更形象的理解。</p>
<ul>
<li>没有客户来的时候，员工们（工作线程）都各自坐在自己的工位上（阻塞在等待信号上）；</li>
<li>有客户来找房子时（任务分发线程发布任务了），大家就会都来争抢这个客户，只有运气最好的一个员工能成功搭话这个客户（被信号量唤醒）；</li>
<li>然后这个员工就会带这个客户出去看房（执行工作任务）。看房的过程通常不会很快，一出去可能就要半天时间（等待慢速的 I/O）。</li>
<li>没抢到客户的员工回到自己的工位上继续等待。</li>
</ul>
<h4 id="1212">12.1.2 信号量的优缺点</h4>
<p>信号量的<strong>优势在于</strong>，当没有任务需要工作线程处理的时候，工作线程可以一直睡眠，而不需要轮询检查任务队列状态，从而<strong>可以避免一些无效的线程唤醒，在总体上减轻整个系统的负担</strong>。</p>
<p>而<strong>信号量的劣势，在于它的重量级</strong>。实际上，信号量是一种 IPC 资源，对信号量操作的如下接口都是系统调用。</p>
<pre><code>int semget(key_t key, int nsems, int semflg);      //创建一组以 key 为标识的信号量
int semctl(int semid, int semnum, int cmd, ...);   //在指定的信号量上执行控制操作
int semop(int semid, struct sembuf *sops, unsigned nsops); //在指定信号量上执行 PV 操作
</code></pre>
<p>更详细的信号量用法，在上述接口的帮助手册中有详细的解释，这里就不再赘述了。</p>
<p><font color="#F39800">信号量配合互斥锁的实现只适用于工作线程对每个任务的处理时间相对较长，而且任务产生的速率比较慢的情形。</font>否则，它会引入严重的竞争消耗，以及不可忽略的系统调用消耗。</p>
<p>而且，这种工作方式<strong>还有一个缺点，就是随着工作线程的增加，锁的竞争会有加剧的趋势</strong>，因为会有更多的线程加入到对共享的任务队列的锁争抢中。</p>
<p>想象一下，如果知名医院的挂号窗口采用房产中介的工作模式，那医院的挂号大厅会乱成什么样子。在这种情形下，需要更高效的工作模式，同时也需要新的同步机制。</p>
<h3 id="122">12.2 条件变量</h3>
<p>再回想一下国内医院挂号窗口的工作方式。国内的知名医院，每天早上都会人山人海（大量任务需要处理），而每个人的挂号时间不会超过几分钟（每个任务的处理时间很短）。</p>
<p>这时候，医院的做法是：</p>
<ul>
<li>每个挂号窗口不会去主动争抢客户（加锁任务队列），而只依次处理在自己窗口下排队的客户（每个工作线程有自己的任务队列）。</li>
<li>来挂号的病人会自己选择队伍最短的窗口去排队，或者有时候大堂保安会负责指挥大家到哪里排队（任务分发线程把任务直接分配到某个工作线程的任务队列）；</li>
<li>在排队人数比较多的时候，医院会开放更多的挂号窗口（启动更多工作线程），因为在不同窗口下的队列之间没有任何竞争关系，新增的挂号窗口能几乎等比地提高处理吞吐量。</li>
</ul>
<p>受这种工作方式的启发，<strong>一个任务量巨大，并且每个任务处理时间很短的系统可以采用这样的工作模式</strong>：</p>
<ul>
<li>每个工作线程都配备自己的任务队列；</li>
<li>任务分发线程根据当前每个工作线程的负载水平，把任务直接追加到负载最低的工作线程的任务队列里去；</li>
<li>当工作线程发现自己的任务队列中已经没有要处理的任务时，自己进入睡眠状态；</li>
<li>任务分发线程在给某个工作线程分配任务时，如果发现分配之前的任务数是 0，就唤醒该工作线程；</li>
<li>工作线程一旦被唤醒，就持续处理自己的任务队列中的所有任务。</li>
</ul>
<p>在这种工作模式中，线程的休眠和唤醒仍然可以使用信号量，此外，还可以使用实现在 ptrhead 库中的更轻量级的条件变量，相关的接口为：</p>
<pre><code>int pthread_cond_wait(pthread_cond_t * cond, pthread_mutex_t *mutex);
int pthread_cond_signal(pthread_cond_t * cond);
int pthread_cond_broadcast(pthread_cond_t *cond);
</code></pre>
<p>其中 pthread_cond_wait() 接口会阻塞一个线程，直到有另外的线程在同一个条件变量 cond 上用  pthread_cond_signal() 或 pthread_cond_broadcast() 发出通知时再继续执行。</p>
<p>pthread_cond_signal 和 pthread_cond_broadcast  的区别在于：</p>
<ul>
<li>pthread_cond_signal 只保证唤醒至少一个被阻塞的线程；</li>
<li>pthread_cond_broadcast 会唤醒所有阻塞在条件变量 cond上的线程。</li>
</ul>
<p><strong>当唤醒目标很明确时，使用 pthread_cond_signal 会更有效率，而且能避免出现惊群的问题</strong>。在上面改进版的任务处理模式中，就应该使用 pthread_cond_signal 来唤醒指定的工作线程。</p>
<p><strong>当唤醒目标无法精确地确定，而只需要保证多个工作线程中至少有一个被唤醒来工作时，应该使用 pthread_cond_broadcast</strong>，但是这时候要注意，每个线程都需要能正确处理多余和虚假的唤醒动作。常见的处理方式是把 pthread_cond_wait 包含于一条 while 循环中：</p>
<pre><code>while(pthread_cond_wait(&amp;cond, &amp;mtx));
// Process the task
</code></pre>
<p>市面上有些高性能的防火墙产品对网络数据包的处理就是采用这种工作模式，有些产品还会使用双缓冲技术，进一步减少任务分发线程与工作线程在操作同一个任务队列时发生锁争抢的概率。</p>
<h3 id="123">12.3 读写锁</h3>
<p>应用中还会遇到一类数据，它们的更新频率很低，但是在多个线程中读取使用的频率很高。对于这类数据，使用互斥锁也能达到保护的目的，程序完全可以正确地运行。但是，<strong>如果临界区比较大，那么对临界区的互斥保护就很容易成为系统的性能瓶颈。而这种情景正是读写锁的用武之地。</strong></p>
<p>读写锁是这样一种锁，它由读锁和写锁两部分组成，读锁是共享的，而写锁是独占的。也就是说：</p>
<ul>
<li>多个读线程可以同时进入临界区，因为临界区内并没有共享数据的更新，所以所有线程都可以正确地工作；</li>
<li>而当有线程试图获取写锁时，如果有读锁，写锁线程会被阻塞，直到所有的读锁都被释放，同时，新的读锁请求也会被阻塞，直到写锁被释放。</li>
</ul>
<p>读写锁的行为有点像游戏服务器停服更新时的做法，发布停服通知后，新登录的用户会被告知服务器正在停服更新，同时服务区会等待一段时间，让当前正在玩的玩家能完成当前正在进行的游戏进程。等所有玩家都下线后，才真正开始执行服务器关闭，更新的操作。</p>
<p>对于更新频率很低的共享数据，使用读写锁代替互斥锁，能<strong>明显提高只读取临界区数据的线程的并行化水平，提高系统处理效率</strong>。但是选用读写锁时<strong>一定要确保临界区数据确实满足上述访问模式</strong>，否则，其最终性能表现可能还不如互斥锁。</p>
<p>pthread 库中读写锁相关的接口定义为：</p>
<pre><code>int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock, 
        const pthread_rwlockattr_t *restrict attr);         //初始化读写锁
int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);       //销毁读写锁
int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);        //加读锁
int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);        //加写锁
</code></pre>
<p>详细的使用方法请参考帮助手册。</p>
<h3 id="124">12.4 自旋锁</h3>
<p>上面介绍的各类锁都会使执行线程在无法成功拿到锁的时候进入休眠，线程下次被唤醒的时间就取决于系统的调度了，这个时间通常是毫秒级的，在系统负载比较高的时候，还会与系统中同时运行的其他线程的运行优先级有关系，唤醒时间可能会更久。</p>
<p>这在一些对实时性要求很高的应用中可能是不能容忍的。同时，<strong>如果要执行的临界区非常短，只是执行有限的几条指令。这种情形下，可以考虑使用自旋锁。</strong></p>
<p>自旋锁在 Linux 内核的中断处理部分有大量的应用，它在遇到锁获取失败时不会挂起当前进程，而是循环持续地再次尝试获取锁，就像一个老板站在程序员的身后，持续不断地催，“弄完了没？弄完了没？”。</p>
<p>自旋锁的<strong>优点是等待时间短</strong>，一旦满足条件就可以马上拿到锁继续执行，不需要经历线程的切换。</p>
<p><strong>它的缺点则是会占用 CPU 资源，一直保持忙等的状态</strong>。</p>
<p>也因为它忙等的特点，只有非常快速就能完成的临界区才适合用自旋锁保护，而且，临界区内一定不能有对同一个临界区的递归调用，否则会发生死锁。</p>
<p>pthread 库中自旋锁相关的接口为：</p>
<pre><code>int pthread_spin_init(pthread_spinlock_t *lock, int pshared);  //初始化自旋锁
int pthread_spin_destroy(pthread_spinlock_t *lock);            //销毁自旋锁
int pthread_spin_lock(pthread_spinlock_t *lock);               //锁定自旋锁
</code></pre>
<p>详细用法请参考帮助手册。</p>
<h3 id="125">12.5 总结</h3>
<p>免费的午餐早已经结束，甚至在移动设备上，多核也已经成为主流，对开发人员来说，多线程开发技术也应该成为标配了。</p>
<p>希望读者通过对本节课的学习，能<strong>对常用的几种线程同步技术有更加形象具体的理解</strong>，能够<strong>更加灵活地应用它们</strong>，从而更加<strong>精准地控制复杂的工作流程</strong>，让系统工作得更加协调，同时更加高效。</p>
<h3 id="126">12.6 答疑与交流</h3>
<blockquote>
  <p><strong>为了方便与作者交流与学习，GitChat 编辑团队组织了一个《攻克 Linux 系统编程》读者交流群，添加小助手-伽利略微信：「GitChatty6」，回复关键字「208」给小助手-伽利略获取入群资格。</strong></p>
</blockquote></div></article>