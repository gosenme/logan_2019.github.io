---
title: 常见同步方式
---

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>常见同步方式</title>
</head>
<body>
<article id="articleDiv" style="overflow: hidden;padding-bottom:20px;text-align: justify;"><div class="mazi-article-content dont-break-out"><p>本节内容：</p>
<ul>
<li>常见同步方式</li>
<li>互斥锁（Mutex）</li>
<li>读写锁（RWMutex）</li>
<li>条件锁（Cond）</li>
<li>信号量（Semaphore）</li>
<li>自旋锁（SpinLock）</li>
<li>原子操作（Atomic）</li>
</ul>
<h3 id="">常见同步方式</h3>
<p>当两个并发单元共享同一个数据的时候需要做<strong>同步</strong>处理，同步处理并不局限于共享同一块内存，当两个进程共享同一个文件给文件加上锁也叫做同步处理。在数据库中启动一个事务或者启动乐观锁，都是同步方式，同步并不局限于内存，两个并发单元不仅仅就是进程中的两个线程，也可能两个进程，甚至两台服务器。共享同一资源都会产生数据竞争，这个时候都需要做同步处理。</p>
<p>我们抛开分布式架构不说，现在就看当两个东西去抢同一份数据的时候在内存同步上究竟怎么做。</p>
<p>比如说 G1、G2 同时共享一份数据的时候，因为 G1、G2 完全可以在线程 T1、T2 上运行，而 T1、T2 完全是在两个核 Core1、Core2 上。他们可以同时执行，就会产生数据竞争（DataRace）效应，我们为了避免数据竞争所以需要对这些数据加锁，加锁就意味着什么呢？说白了锁是一种令牌，谁拿到令牌谁说话，拿不到令牌就等着。</p>
<h3 id="-1">锁</h3>
<p>平常开发中肯定会使用锁这样概念。锁有很多种，例如互斥锁（Mutex）、读写锁（RWMutex）、条件锁（Cond）、信号量（Semaphore）、自旋锁（SpinLock）、原子操作（Atomic），最常见的有哪些锁呢？为了数据竞争我们需要加个锁，它们有不同的性能差别，也就意味着不同的锁适合用在不同的场合，任何时候锁的选择都会很性能有很大关系。</p>
<h3 id="mutex">互斥锁（Mutex）</h3>
<p>互斥就是每次仅允许一个人操作，不区分读写操作，除非这个人把锁给放掉，释放了锁别人才能拿到，否则其他人都得等。</p>
<p>互斥操作有两种实现方式，一种是由内核实现的，一种是由 Runtime 实现的，内核实现的意味着当阻塞的时候内核时间片会被拿走，Runtime 实现的话意味着执行序会被拿走。无论怎么实现都会涉及到上下文切换，所以相对来说代价会比较大。</p>
<p>互斥锁有个特点是递归锁，什么叫递归锁呢？假如 T1 拿到了这把锁，那么接下来再在 T1 上加锁可以么？对于大多数语言是可以的，例如 Java。</p>
<p>两个线程或者两个并发单元会有数据竞争，T1 在线程内部显然没有并发，线程内部就算是协程也是串行的，那也就意味着 T1 已经拿到这把锁了，那再这上面再加锁没有任何影响，因为它还是锁它自己，所以这种情况下我们管它叫递归锁，加锁和解锁数量要完全配对。</p>
<p>但不是所有的语言都支持递归锁。以 Go 语言为例，Go 语言的每个并发单元不是线程，是个 Goroutine，当 G1 拿到了这把锁，它并不能绑定到某个固定的线程上，它有可能中途某种原因被调度到队列，下次被 T2 拿到，那么这把锁实际上是在不同线程当中进行转移。Goroutine 的特点就是它并不会和一个线程进行绑定，它中途会重新放回队列然后在另外线程上恢复，这个时候没有办法确保锁永远是在单个线程上串行的，所以 Go 语言互斥锁不支持递归锁。所以使用其他语言的时候，至于其他语言的互斥能不能支持递归锁和语言实现有很大关系，比如像 Java、C# 的并发单元都是以线程来完成，那么是没有问题的，或者像 Rust，它的并发单元和线程是一比一模型的，永远绑定在一个线程上，那么它也可以用递归锁。Go 语言有可能运行在其他线程，所以递归锁不支持。所以互斥仅能被一个对象拿到，最后是否支持递归锁需要看这种语言的实现方式是否支持，Go 语言不支持递归锁，去重复锁定就会造成死锁。</p>
<p>所以互斥锁是否能重复和递归和语言实现有关系。如果不支持递归锁重复锁定就会造成死锁，所以当选择锁的时候一定要慎重，这个锁支不支持递归，语言对这个实现究竟有哪些限制，否则的话很容易死锁。</p>
<h3 id="rwmutex">读写锁（RWMutex）</h3>
<p>什么情况下才会产生数据竞争，比如一本书同时看有数据竞争么？看的情况下肯定没有数据竞争，因为并不改变这个数据，都去读这个数据而不改变这数据的时候肯定不会有竞争效应。什么情况下有竞争，两个人都去写或者一个读一个写的时候才会产生竞争，所以读写锁是为了改善互斥锁的缺点。</p>
<p>互斥锁的缺点是它不区分读写操作，比如两个人都去读一份数据的时候，就算不去改变数据，他们也是一个一个来排队，这种并发就变成串行的了。而读写锁，你们都去读的时候不用加锁，不加锁意味着不阻塞，所不管多少人去读都没有阻塞的概念，当任意一个人尝试去写的时候，它就会独占锁，所有人都会堵在那，因为它要改变数据，这个时候就会造成阻塞，确保对于所有人来说修改都是同步的。所以读写锁是专门针对并发读行为做优化，它在一定程度上能提升这种互斥锁的性能，因为互斥锁对于读并发也变成串行。所以读写锁意味着对于读并发做优化，所以对于这种我们有一种数据很少去改，但是有大量的客户端去读的时候，我们用读写锁可以在很大程度上提高性能。读写锁算是互斥锁的一种改造版本。</p>
<p>读写锁的好处在于当多个并发单元去读的时候，它不会进行阻塞，因为这个时候数据的状态是稳定的不会被修改，多个人去读没有关系，只有发生写的时候才会发生阻塞锁定，所以它对于读大于写的这种场景很容易提升性能，因为它减少了锁的次数。</p>
<h3 id="cond">条件锁（Cond）</h3>
<p>条件锁是基于锁实现一个条件，我们都可以竞争一把锁，或者说一堆人去竞争一把锁，当其中一个人完成一个操作了以后，它发送一个信号，这个信号有两种激活方式，第一种方式是让阻塞状态的其中一个人激活，第二种方式发送一种广播信号让所有人都激活，这种其实是很常见的。比如说有个通道，有个写，有可能使用批操作一次性往里面去写 1000 条数据，可能有很多人去读，数据有两种状态，一是有次序的，可以每次唤醒其中一个人，第二种一次激活所有的人，使用不同的方式通知。</p>
<p>实际上条件锁是在锁的基础之上实现一个信号通知。因为普通的状态是我们拿到一把锁，释放锁的时候对方才会解除阻塞，如果希望中途给别人发送一个信号呢？就是我暂时不释放这把锁，中途发送一个信号，实际上是利用锁来实现类似消息通知的功能，所以这是锁的另外一种应用。</p>
<p>用锁实现通知，可以让其中一个人激活或者是让多个人同时进行广播激活来实现一种消息，实现一种事件。</p>
<h3 id="semaphore">信号量（Semaphore）</h3>
<p>信号量是什么意思？我们刚才说的锁其实都有很大的特点是需要激活几个人。信号量实际上是限制并发的，比如信号量值设置为 3 就意味着有 3 个并发单元可以同时工作，超过的就在那等，其中有一个退出就加进来一个，这个用于控制并发的。</p>
<p>最常见的做法是 Web 请求，可以用信号量控制当前并发速率，即确保当前并发数量是一万个，超过一万个的就堵在那避免数据库或者服务器被拖垮掉。说白了就是有些资源处理的能力是有限的，必须有一种方式来控制有多少人能使用，就相当于停车场一样，停车场总容量停 10 辆车，超过 10 辆的大家都在那等着，开出去一辆就补进来一辆，但是总数控制在 10 辆。</p>
<p>信号量是用锁来控制并发的数量，超出一个阈值的时候就得等待，其中有任何一个释放了信号量它就可以补进来一个，总共的并发总数限制。</p>
<h3 id="spinlock">自旋锁（SpinLock）</h3>
<p>自旋锁和互斥锁非常像。</p>
<p>它们的区别是时间片的影响，比如说有个时间片，互斥操作在某处阻塞了，除非它拿到锁就继续拿不到就阻塞，这个时候通常情况 CPU 或者 OS 或者 Runtime 会把剩下来的时间片拿走，用来执行另外一个并发单元。</p>
<p>互斥锁造成阻塞，如果是 OS 实现的内核互斥对象，那么时间片就会被操作系统拿走，如果 Runtime 实现的，那么 Runtime 会把剩下的时间片拿走，可能就是 M/P 组合去执行另外一个任务。所以说这种互斥锁比较适合大粒度的锁定，因为下次拿到锁的时候是由 OS 内核或者 Runtime 来通知，重新分配时间片去激活，所以互斥锁的粒度相对来说比较大。</p>
<p>自旋锁通常用来快速锁定。比如说执行一个锁非常短，没有必要把时间片浪费出去，因为拿走时间片都要做调度甚至要做上下文切换的，这种代价是很大的。有些时候我们需要做很短的时间锁定，比如说只是做很简单的原子操作，或者一个请求逻辑很快就可以返回，不希望做一次调度把我的时间片让出去，那怎么设计？可以设计 for 循环检查如果 OK 就跳出循环继续执行，如果没有 OK 就继续循环，相当于 for 循环不停的去检查，因为这个时间很短就能返回，这样不需要做控制权的移交，也不需要做上下文的移交。</p>
<p>自旋锁适合做非常短的操作，否则的话不但会浪费时间片而且会把 CPU 跑满，因为不停的做循环，这个循环非常的快，内部就是简单的判断指令很容易 CPU 跑满，而是时间太长可能其它的并发单元会被饿死掉。所以自旋锁是用来处理极短时间之内的这种锁定，它的好处是不需要让出时间片不需要做上下文切换。</p>
<p>自旋锁的好处相对于互斥用于极短时间内的等待，好处是不会让出时间片不会有上下文切换。但是一定要记住，因为它通常是由循环来实现的，所以它会消耗很高的 CPU 资源，如果消耗时间非常长用自旋锁的话可能会导致很严重的问题。对于极短时间内的自旋锁操作，因为它节省了上下文切换，节省了时间片，所以它的效率会很高，选择互斥还是选择自旋完全看你的算法究竟侧重于哪个方面。</p>
<h3 id="atomic">原子操作（Atomic）</h3>
<p>原子操作实际上是用来控制内存操作的事务性，原子操作最常见的做法是用 CAS，用原子操作可以实现 Lock-free，就是所谓的无锁并发。</p>
<p>原子操作是在汇编层面上实现的，或者说是由 CPU 指令来实现的，它的好处是实现类似 lock-free 就是说不用显式的加锁就能保证对多个并发对同一份数据操作的安全性。</p>
<p>下篇内容将重点介绍一下原子操作。</p>
<p>所以锁比你想象复杂的多，甚至还可以看到远远不止这六种锁，有各种各样的锁，但更多的是在这六种之上进行更多的整合、组合或者是变形来实现在不同的算法需求下进行数据竞争的保护，很多时候我们在数据结构里面发现同时使用多把锁，比如 pipe 会使用三把锁和两个 Cond，所以锁除了用来保护数据以外，通常还用来控制逻辑的执行。我们对锁的使用往往会非常复杂，甚至对锁的组合使用有很多种变形，这就需要我们平时做大量的练习大量的阅读，看看在不同的数据结构下对于锁的使用究竟做了哪些变形。</p>
<p>任何锁的使用都会影响性能，如果选错的话影响会很大的。</p></div></article>
</body>
</html>