---
title: C_C++ 多线程编程精髓-20
---
<article id="topicContainer" class="column_content"><h2 class="topic_title"></h2><div><p>关于锁的使用，根据我的经验总结如下几点。</p>
<h3 id="">减少锁的使用</h3>
<p>实际开发中能不使用锁尽量不使用锁，当然这不是绝对的，如果使用锁也能满足性能要求，使用也无妨，一般使用了锁的代码会带来如下性能损失：</p>
<ul>
<li>加锁和解锁操作，本身有一定的开销；</li>
<li>临界区的代码不能并发执行；</li>
<li>进入临界区的次数过于频繁，线程之间对临界区的争夺太过激烈，若线程竞争互斥量失败，就会陷入阻塞，让出 CPU，因此执行上下文切换的次数要远远多于不使用互斥量的版本。</li>
</ul>
<p>替代锁的方式有很多，如无锁队列。</p>
<h3 id="-1">明确锁的范围</h3>
<p>看下面这段代码：</p>
<pre><code>if(hashtable.is_empty())
{
    pthread_mutex_lock(&amp;mutex);
    htable_insert(hashtable, &amp;elem);
    pthread_mutex_unlock(&amp;mutex);
}
</code></pre>
<p>读者能看出这段代码的问题吗？代码行 <strong>4</strong> 虽然对 <strong>hashtable</strong> 的插入使用了锁做保护，但是判断 <strong>hash_table</strong> 是否为空也需要使用锁保护，因此正确的写法应该是：</p>
<pre><code>pthread_mutex_lock(&amp;mutex);
if(hashtable.is_empty())
{   
    htable_insert(hashtable, &amp;elem);  
}
pthread_mutex_unlock(&amp;mutex);
</code></pre>
<h3 id="-2">减少锁的粒度</h3>
<p>所谓减小锁使用粒度指的是尽量减小锁作用的临界区代码范围，临界区的代码范围越小，多个线程排队进入临界区的时间就会越短。这就类似高速公路上堵车，如果堵车的路段越长，那么后续过来的车辆通行等待时间就会越长。</p>
<p>我们来看两个具体的例子：</p>
<p><strong>示例一</strong></p>
<pre><code>void TaskPool::addTask(Task* task)
{
    std::lock_guard&lt;std::mutex&gt; guard(m_mutexList); 
    std::shared_ptr&lt;Task&gt; spTask;
    spTask.reset(task);            
    m_taskList.push_back(spTask);

    m_cv.notify_one();
}
</code></pre>
<p>上述代码中 <strong>guard</strong> 锁保护 <strong>m_taskList</strong>，仔细分析下这段代码发现，代码行 <strong>4</strong>、<strong>5</strong> 和 <strong>8</strong> 行其实没必要作为临界区内的代码的，因此建议挪到临界区外面去，修改如下：</p>
<pre><code>void TaskPool::addTask(Task* task)
{
    std::shared_ptr&lt;Task&gt; spTask;
    spTask.reset(task);

    {
        std::lock_guard&lt;std::mutex&gt; guard(m_mutexList);             
        m_taskList.push_back(spTask);
    }

    m_cv.notify_one();
}
</code></pre>
<p>修改之后，<strong>guard</strong> 锁的作用范围就是 <strong>7</strong> 、<strong>8</strong> 两行了，仅对 <strong>m_taskList.push_back()</strong> 操作做保护，这样锁的粒度就变小了。</p>
<p><strong>示例二</strong></p>
<pre><code>void EventLoop::doPendingFunctors()
{
    std::unique_lock&lt;std::mutex&gt; lock(mutex_);
    for (size_t i = 0; i &lt; pendingFunctors_.size(); ++i)
    {
        pendingFunctors_[i]();
    }
}
</code></pre>
<p>上述代码中 <strong>pendingFunctors_</strong> 是被锁保护的对象，它的类型是 <strong><code>std::vector&lt;Functor&gt;</code></strong>，这样的代码效率比较低，必须等当前线程挨个处理完 <strong>pendingFunctors_</strong> 中的元素后其他线程才能操作 <strong>pendingFunctors_</strong> 。修改代码如下：</p>
<pre><code>void EventLoop::doPendingFunctors()
{
    std::vector&lt;Functor&gt; functors;

    {
        std::unique_lock&lt;std::mutex&gt; lock(mutex_);
        functors.swap(pendingFunctors_);
    }

    for (size_t i = 0; i &lt; functors.size(); ++i)
    {
        functors[i]();
    }   
}
</code></pre>
<p>修改之后的代码使用了一个局部变量 <strong>functors</strong>，然后把 <strong>pendingFunctors_</strong> 中的内容倒换到 <strong>functors</strong> 中，这样就可以释放锁了，允许其他线程操作 <strong>pendingFunctors_</strong> ，现在只要继续操作本地对象 <strong>functors</strong> 就可以了，提高了效率。</p>
<h3 id="-3">避免死锁的一些建议</h3>
<ul>
<li><strong>一个函数中，如果有一个加锁操作，那么一定要记得在函数退出时记得解锁，且每个退出路径上都不要忘记解锁路径</strong>。例如：</li>
</ul>
<pre><code>  void some_func()
  {
      //加锁代码

      if (条件1)
      {
          //其他代码
          //解锁代码
          return;
      } 
      else
      {
          //其他代码
          //解锁代码
          return;
      }


      if (条件2)
      {
          if (条件3)
          {
              //其他代码
              //解锁代码
              return;
          }

          if (条件4)
          {
              //其他代码
              //解锁代码
              return;
          }   
      } 

      while (条件5)
      {
          if (条件6)
          {
              //其他代码
              //解锁代码
              return;
          }
      }
  }
</code></pre>
<p>上述函数中每个逻辑出口处都需要写上解锁代码。前面也说过，这种逻辑非常容易因为疏忽忘记在某个地方加上解锁代码而造成死锁，因此一般建议使用 RAII 技术将加锁和解锁代码封装起来。</p>
<ul>
<li><strong>线程退出时一定要及时释放其持有的锁</strong></li>
</ul>
<p>实际开发中会因一些特殊需求创建一些临时线程，这些线程执行完相应的任务后就会退出。对于这类线程，如果其持有了锁，一定记得在线程退出时记得释放其持有的锁对象。</p>
<ul>
<li><strong>多线程请求锁的方向要一致，以避免死锁</strong></li>
</ul>
<p>假设现在有两个锁 A 和 B，线程 1 在请求了锁 A 之后再请求 B，线程 2 在请求了锁 B 后再请求锁 A，这种线程请求锁的方向就不一致了，线程 1 的方向是从 A 到 B，线程 2 的方向是从 B 到 A，多个线程请求锁的方向不一致容易造成死锁。因此建议的方式是线程 1 和 线程 2 请求锁的方向保持一致，要么都从 A 到 B，要么都从 B 到 A。</p>
<ul>
<li><strong>当需要同一个线程重复请求一个锁时，搞清楚你所使用的锁的行为，是递增锁引用计数，还是会阻塞抑或是直接获得锁？</strong></li>
</ul>
<h3 id="-4">避免活锁的一些建议</h3>
<p>前面说了避免“死锁”，读者应该能理解，但是这里突然出现了避免“活锁”，我相信很多人看到这个标题一下子就懵了。所谓活锁就是，当多个线程使用 <strong>trylock</strong> 系列的函数时，由于多个线程相互谦让，导致即使在某段时间内锁资源是可用的，也可能导致需要锁的线程拿不到锁。举个生活中的例子，马路上两个人迎面走来，两个人同时往一个方向避让，原来本意是给对方让路，结果还是发生了碰撞。</p>
<p>我们在实际编码时，尽量避免不要过多的线程使用 <strong>trylock</strong> 请求锁，以免出现“活锁”现象，这是对资源的一种浪费。</p>
<h3 id="-5">总结</h3>
<p>从第 08 节到 第 17 节我们介绍 Windows 和 Linux 操作系统 API 层面上的各种常用多线程同步对象，本节是对它们的使用做了一个规范性和效率性总结。学会使用锁并不难，如何高效地使用它们则是一个不断积累不断总结的过程，希望本节的经验能对读者有帮助。同时，本节介绍锁的注意事项也适用于其他编程语言。</p>
<p><a href="https://github.com/balloonwj/gitchat_cppmultithreadprogramming">点击这里下载课程源代码</a>。</p></div></article>