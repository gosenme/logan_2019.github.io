---
title: PostgreSQL 优化器入门-23
---
<article id="topicContainer" class="column_content"><h2 class="topic_title"></h2><div><p>连接路径中包括嵌套循环连接、哈希连接和归并连接，本文主要介绍嵌套循环连接和哈希连接的一些特点。</p>
<p>假设有 2 个表，他们的数据分别如下：</p>
<p>TEST_A 表：</p>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>TEST_B 表：</p>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<h3 id="">嵌套循环连接的流程</h3>
<p>我们假设这两个表做连接的 SQL 语句生成了一个嵌套循环连接：</p>
<pre><code>SELECT * FROM TEST_A a, TEST_B b WHERE a.a = b.a;
</code></pre>
<p>首先，嵌套循环连接的结点会向外表的 SeqScan 拉取一条元组。在获得这条元组之后，嵌套循环连接需要把这条元组记录到自己的上下文里，因为这条元组要和内表的左右元组去尝试做连接操作，而 PostgreSQL 的执行器是“一次一元组”的，所以内表的每条元组都需要使用到这个外表元组。</p>
<div style="text-align:center">
<img src="https://images.gitbook.cn/3f9cbc00-d6d3-11e8-9d3a-e5c2f8f2166f" width="400px" /></div>
<p></br></p>
<p>获得外表元组之后，就可以尝试去内表拉取一条元组：</p>
<div style="text-align:center">
<img src="https://images.gitbook.cn/4c333cf0-d6d3-11e8-bc37-b356bf4bd057" width="400px" /></div>
<p></br></p>
<p>内表和外表的元组都准备好之后，就开始执行约束条件，查看这两个元组是否满足连接条件的要求：</p>
<div style="text-align:center">
<img src="https://images.gitbook.cn/599ff9a0-d6d3-11e8-be45-7958f66a47cf" width="400px" /></div>
<p></br></p>
<p>如果不满足需求，则再次从内表拉取一条元组：</p>
<div style="text-align:center">
<img src="https://images.gitbook.cn/6507e5a0-d6d3-11e8-bc37-b356bf4bd057" width="400px" /></div>
<p></br></p>
<p>再次拉取来的元组仍然不满足连接条件，还需要继续从内表拉取元组：</p>
<div style="text-align:center">
<img src="https://images.gitbook.cn/6f3e2f70-d6d3-11e8-9863-8160edfadb87" width="400px" /></div>
<p></br></p>
<p>从内表拉取来的元组是 NULL，代表内表扫描结束了，这时候外表要换下一条元组了。需要注意的是，前面我们换了外表元组，也就是说这个外表元组要重新和内表的元组再一次尝试连接操作，这时候需要把内表重置一下。原因是内表的上下文记录的是当前的最后一条元组，重置是为了让它重新开始指向最开始的元组。</p>
<div style="text-align:center">
<img src="https://images.gitbook.cn/7cb1a2e0-d6d3-11e8-be45-7958f66a47cf" width="400px" /></div>
<p></br></p>
<p>获得新的外表元组：</p>
<div style="text-align:center">
<img src="https://images.gitbook.cn/86ac1c30-d6d3-11e8-9863-8160edfadb87" width="400px" /></div>
<p></br></p>
<p>获得新的内表元组：</p>
<div style="text-align:center">
<img src="https://images.gitbook.cn/973c8710-d6d3-11e8-be45-7958f66a47cf" width="400px" /></div>
<p></br></p>
<p>这两个元组符合连接条件：</p>
<div style="text-align:center">
<img src="https://images.gitbook.cn/a0650a60-d6d3-11e8-be45-7958f66a47cf" width="400px" /></div>
<p></br></p>
<p>还需要根据投影的需要，借助这两个元组来生成新的投影，然后把投影元组返回给上层结点：</p>
<div style="text-align:center">
<img src="https://images.gitbook.cn/aadbb890-d6d3-11e8-9863-8160edfadb87" width="400px" /></div>
<p></br></p>
<p>以此类推，嵌套循环连接是一个O(N^2)复杂度的物理操作。</p>
<h3 id="-1">哈希连接的注意事项</h3>
<p>我们查看一下 PostgreSQL 对上面示例中的 SQL 语句生成了什么样的执行计划：</p>
<pre><code>postgres=# EXPLAIN SELECT * FROM TEST_A a, TEST_B b WHERE a.a = b.a;
                             QUERY PLAN
---------------------------------------------------------------------
 Hash Join  (cost=1.07..2.14 rows=3 width=32)
   Hash Cond: (a.a = b.a)
   -&gt;  Seq Scan on test_a a  (cost=0.00..1.03 rows=3 width=16)
   -&gt;  Hash  (cost=1.03..1.03 rows=3 width=16)
         -&gt;  Seq Scan on test_b b  (cost=0.00..1.03 rows=3 width=16)
(5 rows)
</code></pre>
<p>从示例的执行计划中可以看出，这两个表做连接的时候进行的是哈希连接，这种方法是参与连接操作的内表表达成一个哈希表的形式，创建哈希表的过程是一个循环的过程，我们可以简单地描述为：</p>
<pre><code>1. 从 test\_b 表获得一条记录（元组）；
2. 如果元组为 NULL，代表 test\_b 中的表已经处理完毕，哈希表创建完毕；
3. 将记录插入到哈希表，跳转到步骤 1。
</code></pre>
<p>在这个过程中需要注意两点：</p>
<ul>
<li><p>创建哈希表所有的哈希源自 SQL 语句中的 "a.a = b.a"，也就是说计算哈希值的时候使用的是 test_b.a 这个列。我们之前曾经说明过，如果没有连接条件（即所谓的 "a.a = b.a"), PostgreSQL 只会生成嵌套循环连接，不会产生哈希连接或者归并连接。使用 test_b.a 来计算哈希值的好处显而易见，因为我们的连接结果最终要满足 "a.a = b.a" 这样的条件。我们可以通过 test_a.a 的哈希值和 test_b.a 的哈希值是否匹配来缩小算法的复杂性。本来嵌套循环连接过程中，每个外表元组都需要匹配内表元组，也就是说每个外表元组，都要扫描一次内表；但现在使用哈希值来匹配，就缩小了内表元组的匹配范围，通过增加哈希表存储的空间来换取连接操作的计算时间。</p></li>
<li><p>创建哈希表的过程中不会产生元组，也就是说产生哈希表所带来的代价是启动代价。从示例的执行计划中就可以看出，"SeqScan Test_b" 的过程中并没有启动代价，因为对于 "SeqScan Test_b" 来说，它获得的第一条元组就直接返回给“上层”了。但是它的上层结点是哈希，也就是创建哈希表，只要哈希表没有创建完，它就不可能给“上层”返回元组。直到 test_b 中的所有元组都处理完，哈希表建立成功，才会返回第一条元组。所以启动代价看上去就是顺序扫描的代价（关于哈希结点这个代价是否准确的问题请参考《第18课：连接代价和 Non-SPJ 代价》）。</p></li>
</ul>
<p>哈希表创建成功之后，等于是将内表的元组做完了“预处理”，外表的元组就可以逐条来哈希表里探测。这个探测过程的时间复杂度和我们平时的哈希查找的复杂度是一样的，就是对外表的列计算哈希值，然后根据哈希值在哈希表中找到对应的“桶”，然后就可以去桶里进行筛选了，流程如下：</p>
<pre><code>1.从外表获得一条元组；
2.元组如果为 NULL，那么证明外表已经扫描完毕，这次连接操作就执行完成了；
3.根据元组中的数据计算哈希值，然后去哈希表里找到对应的“桶”；
4.如果没有找到桶，那么证明这条元组不可能和内表产生连接结果，放弃这条元组，转到步骤 1；
5.如果找到了“桶”，那么这个“桶”里保存的是**有可能**和当前的表产生连接的元组；
6.尝试从桶中找到符合连接条件的一个元组；
7.如果不能从“桶中”找到这样的元组，跳转到步骤 1；
8.如果能从“桶”中找到这样的元组，产生连接结果，返回给“上层”，跳转到步骤 6。
</code></pre>
<p>通常而言，我们给出的示例过于简单。我们经常会有这样一个结论——在使用哈希连接的时候，通常“会用较小的表来创建哈希表”。这种表达方式非常不科学，什么样的表叫做比较小的表呢？假设我们有一个表的数据量是 1T，另一个表的数据量是 0.5T，相对而言，0.5T 的表就是小表，但是用它来创建哈希表，也可能带来灾难性的后果。</p>
<p>使用小表来创建哈希表的目的是想让这个小表创建的哈希表能够直接保存在内存里，这样的话就不会产生磁盘 IO，无论外表有多少元组来哈希表里探测，哈希表都不会产生 IO 代价，只会产生 CPU 代价。这种假设过于完美了，生活并非万事顺遂，如果遇到了“小表”也非常大的情况，那该如何是好呢？</p>
<p>如果我们想逃避问题，可以说遇到这种情况就不要选择哈希连接了。这种推卸责任的做法肯定是会受到嵌套循环连接和归并连接鄙视的，因此，我们选择直面问题，看看有哪些解决方案。</p>
<p>现在的问题是要创建哈希表的表非常大，内存里保存不下。我们可以在内存<strong>即将</strong>保存不下的时候，停止继续向哈希表插入新的数据，转而从这时候开始，遍历外表的元组，来“不完整”的哈希表中探测。如果能产生执行结果就返回给上层，这样的复杂度是：</p>
<pre><code>创建不完整哈希表的代价 + 外表遍历一次的代价
</code></pre>
<p>等外表遍历一次之后，我们就把当前的哈希表销毁掉，然后继续再扫描内表，使用内表中剩余的元组继续创建新的哈希表，直到再次出现内存中<strong>即将</strong>保存不下的时候，再次停止访问内表，转回头重新遍历外表，以此类推。</p>
<p>这样带来的好处是，哈希表永远都只在内存中，永远也不会产生 IO 代价；而带来的坏处是，对于每个“不完整”的哈希表，都要扫描一次外表。假设外表有 M 条元组，内表有 N 条元组，内表要创建 X 个哈希表，那么这种算法的复杂度就是：</p>
<pre><code>M * X + N
</code></pre>
<p>虽然不使用 IO 挺好的，但是外表要扫描多次，尤其在外表是大表的情况下，扫描多次的代价也不小。那么，还有没有其他方法来实现哈希连接呢？实际上还可以考虑“使用 IO”，也就是说把哈希表做一个“物化”。</p>
<p>但如果只简单地把哈希表做一个物化，看上去也并不能带来什么好处，因为这会带来频繁的换页 IO，我们考虑一种极端的情况：</p>
<pre><code>假如创建了一个物化的哈希表，这个哈希表有一小部分在内存中，另一部分在磁盘上物化。从外表获得一条元组之后发现，和它具有连接结果的内表元组恰好是保存在哈希表的磁盘部分，这时候就需要把这部分哈希表加载到磁盘，然后得到对应的内表元组和外表做连接。

第一条外表元组处理完毕之后，开始处理第二条外表元组。这时候又发现和第二条外表元组具有连接结果的内表的元组又出现在哈希表的磁盘部分，还要把这部分加载到内存。

以此类推，每一条外表元组对应的内表元组都在磁盘上，都会带来磁盘 IO，这种结果还是很恐怖的。
</code></pre>
<p>PostgreSQL 采用的是什么方法呢？它采用了区分 Batch 的方法，在创建哈希表的时候，就会同时计算一个哈希表需要不需要分 Batch，需要分几个 Batch。所谓的 Batch 就是把原来所谓的哈希表分成了多个，其中一个 Batch 以哈希表的形式保存在内存中，其他的 Batch 都物化到磁盘上。</p>
<p>因此哈希连接的第一个步骤是，创建哈希表的时候就是对内表创建 Batch 的情况，Batch 的数量由哈希表的容量决定。假如一个表有 100M 数据，而可以用来创建哈希表的空间有 1M，那么它就需要 100 个 Batch。但是，PostgreSQL 期望这个值是一个 2 的幂次方，所以它会创建 128 个 Batch。</p>
<p>每个 Batch 里又会有多个 Bucket，假设每个元组的大小是 1K，每个 Bucket 中可以有 10 个元组，那么最终可以有 102.4 个 Bucket，同样取成 2 的幂次方得到的 Bucket 数也是 128（注意：PostgreSQL 还考虑了一些头部的大小，为了方便计算，我们忽略这些内容）。</p>
<p>当拿到一条内表元组，需要计算这条元组对应的哈希值，这个哈希值是一个 32 位的整数。假设这个哈希值是 X，则可以这样确定这条元组属于哪个 Batch 以及属于哪个 Bucket：</p>
<pre><code>rs_logn = 对 Bucket 数求以 2 为底的对数
所属 Batch = (X&gt;&gt;rs_logn) % Batch 数
所属 Bucket = X % Bucket 数
</code></pre>
<p>在获得了元组所属的 Batch 和 Bucket 后，还需要看一下这个 Batch 是否在内存中。因为内存中可以维护一个 Batch（Batch 在内存中是哈希表的形式），如果对应的 Batch 在内存中，就可以把元组直接插入内存中的哈希表；如果对应的 Batch 是物化的文件，那么就把元组写入对应 Batch 文件对应的 Bucket 中。</p>
<p>PostgreSQL 在内存中以哈希表的形式维护了一个 Batch。有时候数据倾斜可能导致 Batch 中的数据特别多，在内存中保存不下了，于是 PostgreSQL 这时候可以扩大 Batch 数量的大小。比如原来是 128 个 Batch，现在直接变成 256 个。然后所有的数据都会“大迁移”，但这也是没办法的事。</p>
<p>实际上 PostgreSQL 对数据倾斜的情况做了特殊处理。大家如果查阅《第12课：统计信息》可以发现，我们统计了数据的高频值，也就是说在一个列中频繁出现的某个特殊值我们已经记录下来了。这时候 PostgreSQL 就决定独立于哈希表另外创建一个类似的哈希子表，尽量把这些数据保存在内存中。但天有不测风云，如果这些高频值太多了，多到内存中放不下，仍然还是要被物化出去。</p>
<p>在把内表进行哈希化之后，就会产生一个内存中维护的哈希表形式的 Batch 和一堆物化的 Batch。内表一旦全部处理完毕，就可以开始处理外表了。和之前一样，外表的每条元组来哈希表里探测，但它只能在内存中的哈希表中探测，无法探测物化的 Batch，这时候我们怎么办呢？当然可以考虑在匹配到某个物化 Batch 的时候把这个 Batch 切换到内存中，把内存中的 Batch 物化掉，但是这种频繁的切换会降低性能。</p>
<p>PostgreSQL 的做法是在获取到一个外表元组之后，先计算它属于哪个 Batch 以及 Bucket。如果发现对应的 Batch 恰好是内存中维护的那个，它就直接探测获得结果了；但如果发现不是内存中维护的那个，而是一个物化的 Batch 文件，这时候我们也不放过这个外表元组，我们把它保存到**外表的 Batch **中。</p>
<p>也就是说每个内表的 Batch，都会有一个对应的外表的 Batch。外表的元组或者直接探测，或者保存到外表的 Batch 中，这样在外表扫描一遍之后，我们就可以逐个 Batch 进行匹配。</p>
<h3 id="-2">小结</h3>
<p>我们之前简单地计算过哈希连接的代价，但是没有计算分 Batch 的情况。实际上，PostgreSQL 在进行代价计算的时候充分考虑了这些情况。如果对代价计算的实际过程感兴趣，还是需要去研究 PostgreSQL 的优化器的源码。</p></div></article>